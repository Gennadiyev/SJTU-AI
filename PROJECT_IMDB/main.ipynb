{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da58061d",
   "metadata": {},
   "source": [
    "# First Attempt implementing FC neural network in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "274cd885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # God please write code for me"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb964720",
   "metadata": {},
   "source": [
    "## Problem Description\n",
    "\n",
    "The aim of the model is to estimate the [IMDB](https://www.imdb.com) score of the a movie, based on:\n",
    "\n",
    "- Name\n",
    "- Release Date\n",
    "- Production Budget\n",
    "- Genre\n",
    "- Worldwide Gross\n",
    "- Run Time\n",
    "\n",
    "We then try to identify this relationship.\n",
    "\n",
    "$$\\left.\n",
    "\\begin{array}{l}\n",
    "\\text{Film Name} \\\\\n",
    "\\text{Release Date} \\\\\n",
    "\\text{Production Budget} \\\\\n",
    "\\text{Genre} \\\\\n",
    "\\text{Worldwide Gross} \\\\\n",
    "\\text{Run Time}\n",
    "\\end{array}\n",
    "\\right\\}\\Rightarrow\\text{IMDB Rating}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac65ed7",
   "metadata": {},
   "source": [
    "## Data Source\n",
    "\n",
    "The data source comes from [here](https://vega.github.io/editor/data/movies.json), licensed under MIT License.\n",
    "\n",
    "## Preprocessing\n",
    "\n",
    "For preprocessing, I used a combination of Lua and Python.\n",
    "\n",
    "### Filter\n",
    "\n",
    "The original JSON file has more than 3000 films, but many of which has missing information.\n",
    "\n",
    "The `preprocess.lua` **filters out all entries without any one of the following parameters**:\n",
    "\n",
    "- Film Name (`Title`)\n",
    "- Release Date (`Release Date`)\n",
    "- Production Budget (`Production Budget`)\n",
    "- Genre (`Main Genre`)\n",
    "- Worldwide Gross (`Worldwide Gross`)\n",
    "- Run Time (`Running Time min`)\n",
    "- IMDB Rating (`IMBD Rating`)\n",
    "\n",
    "After filtering, **1141 films** survived with **12 different genres**:\n",
    "\n",
    "```json\n",
    "[\"Action\",\"Black Comedy\",\"Comedy\",\"Adventure\",\"Drama\",\"Romantic Comedy\",\"Horror\",\"Thriller/Suspense\",\"Musical\",\"Documentary\",\"Western\",\"Concert/Performance\"]\n",
    "```\n",
    "\n",
    "The list of movies that survived is stored in `movies_processed.json`.\n",
    "\n",
    "The list of genres are stored in `genres.json`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9a516e",
   "metadata": {},
   "source": [
    "### Encoding\n",
    "\n",
    "Before feeding the data into the FC neural network, we first need to find a way to encode the data into a list of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a28f4096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1140 movies found with 12 genres.\n"
     ]
    }
   ],
   "source": [
    "import json, os\n",
    "\n",
    "with open(\"genres.json\") as f:\n",
    "    Genres = json.loads(f.read())\n",
    "with open(\"movies_processed.json\") as f:\n",
    "    Movies = json.loads(f.read())\n",
    "print(\"%d movies found with %d genres.\" % (len(Movies), len(Genres)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d3c304",
   "metadata": {},
   "source": [
    "### Input and Output\n",
    "\n",
    "We'll input all information of a movie into a FC network. But before doing so, proper encoding is necessary.\n",
    "\n",
    "#### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b28f1581",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIN @ B (66)\n",
      "MAX @ B (66)\n",
      "MAX @ r (114)\n",
      "MIN @   (32)\n",
      "MAX @ w (119)\n",
      "MAX @ z (122)\n",
      "MAX @ È (200)\n",
      "MAX @ ‡ (8225)\n",
      "maxLen = 58\n",
      "maxAscii = 8225\n",
      "minAscii = 32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "EncodedInput = []\n",
    "\n",
    "# Titles: stats\n",
    "maxLen = -1\n",
    "maxAscii = -1\n",
    "minAscii = np.Infinity\n",
    "for i in Movies:\n",
    "    t = str(i['Title'])\n",
    "    if len(t) > maxLen:\n",
    "        maxLen = len(t)\n",
    "    for char in t:\n",
    "        if ord(char) < minAscii:\n",
    "            minAscii = ord(char)\n",
    "            print(\"MIN @\", char, \"({0})\".format(ord(char)))\n",
    "        if ord(char) > maxAscii:\n",
    "            maxAscii = ord(char)\n",
    "            print(\"MAX @\", char, \"({0})\".format(ord(char)))\n",
    "print('maxLen = {0}\\nmaxAscii = {1}\\nminAscii = {2}'.format(maxLen, maxAscii, minAscii))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58473fc0",
   "metadata": {},
   "source": [
    "In the above snippet we found that the maximum length for a title is 58. Several strange symbols are found in addition to regular `(space)` to `z` in ASCII representations. To encode the title, any character with `ord(char) > 122 or ord(char) < 32` will be **clamped** into the range.\n",
    "\n",
    "The following code implements such encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d7fb1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broken Arrow [66, 114, 111, 107, 101, 110, 32, 65, 114, 114, 111, 119, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Clamping function\n",
    "def clamp(val, valMin, valMax):\n",
    "    if val > valMax:\n",
    "        return valMax, True\n",
    "    elif val < valMin:\n",
    "        return valMin, True\n",
    "    else:\n",
    "        return val, False\n",
    "\n",
    "# ASCII encode\n",
    "TitleEncoded = list(list(clamp(ord(char), 32, 122)[0] for char in str(i[\"Title\"])) for i in Movies)\n",
    "# Extending to maxLen\n",
    "TitleEncoded = list(i + [0] * (maxLen - len(i)) for i in TitleEncoded)\n",
    "\n",
    "# Confirmation\n",
    "print(Movies[0][\"Title\"], TitleEncoded[0])\n",
    "\n",
    "# Add to EncodedInput\n",
    "EncodedInput.append(TitleEncoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5200b5",
   "metadata": {},
   "source": [
    "The title in its ASCII form will be given as input to the neural network in **an array of 58 integers** ranging from 32 to 122.\n",
    "\n",
    "---\n",
    "\n",
    "Before moving on, define the following normalization function first. It maps an array of data into an array of float between `normMin` and `normMax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3420c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(arr, normMin, normMax):\n",
    "    inMin, inMax = min(arr), max(arr)\n",
    "    return list(map(lambda val: (val - inMin) / (inMax - inMin) * (normMax - normMin) + normMin, arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c3fa1f",
   "metadata": {},
   "source": [
    "Then we'll move on to release dates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "782f7a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Release Date Timestamps ranges from 3296736.0 to 22074912.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Example: Jul 25 2008\n",
    "Timestamps = list(time.mktime(time.strptime(i[\"Release Date\"], \"%b %d %Y\")) / 100 for i in Movies)\n",
    "print(\"Release Date Timestamps ranges from\", min(Timestamps), \"to\", max(Timestamps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5845b684",
   "metadata": {},
   "source": [
    "In the above snippet we found that the time starts with a big integer and has a rather big range. To normalize the time (foundamentally logical because time is consecutive), we set a linear normalization function to clamp all ranges into $[0,\\,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab596921",
   "metadata": {},
   "outputs": [],
   "source": [
    "NormalizedTimestamps = normalize(Timestamps, 0, 1)\n",
    "# Add to EncodedInput\n",
    "EncodedInput.append(list([i] for i in NormalizedTimestamps))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39208d19",
   "metadata": {},
   "source": [
    "The timestamps takes **1** float value when given as input to the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90193ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21664838846239745 65000000\n"
     ]
    }
   ],
   "source": [
    "NormalizedProductionBudgets = normalize(list(i[\"Production Budget\"] for i in Movies), 0, 1)\n",
    "print(NormalizedProductionBudgets[0], Movies[0][\"Production Budget\"])\n",
    "EncodedInput.append(list([i] for i in NormalizedProductionBudgets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a426144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Action\n"
     ]
    }
   ],
   "source": [
    "def getGenreId(str):\n",
    "    return Genres.index(str)\n",
    "GenreId = list(map(getGenreId, list(i[\"Major Genre\"] for i in Movies)))\n",
    "print(GenreId[0], Movies[0][\"Major Genre\"])\n",
    "EncodedInput.append(list([i] for i in GenreId))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65fd0f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08049054258816266 148345997\n"
     ]
    }
   ],
   "source": [
    "NormalizedWorldwideGross = normalize(list(i[\"Worldwide Gross\"] for i in Movies), 0, 1)\n",
    "print(NormalizedWorldwideGross[0], Movies[0][\"Worldwide Gross\"])\n",
    "EncodedInput.append(list([i] for i in NormalizedWorldwideGross))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a2281a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "EncodedInput.append(list([i[\"Running Time min\"]] for i in Movies))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112895f5",
   "metadata": {},
   "source": [
    "Before finishing, let's check the final results in `EncodedInput`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bdc767a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "[[66, 114, 111, 107, 101, 110, 32, 65, 114, 114, 111, 119, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0.26313610011962824], [0.21664838846239745], [0], [0.08049054258816266], [108]] {'IMDB Votes': 33584, 'Production Budget': 65000000, 'IMDB Rating': 5.8, 'MPAA Rating': 'R', 'Rotten Tomatoes Rating': 55, 'Distributor': '20th Century Fox', 'Director': 'John Woo', 'Creative Type': 'Contemporary Fiction', 'US Gross': 70645997, 'Major Genre': 'Action', 'Worldwide Gross': 148345997, 'Source': 'Original Screenplay', 'Release Date': 'Feb 09 1996', 'Running Time min': 108, 'Title': 'Broken Arrow'}\n"
     ]
    }
   ],
   "source": [
    "print(len(EncodedInput))\n",
    "print(list(i[0] for i in EncodedInput), Movies[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2de54a",
   "metadata": {},
   "source": [
    "Now we can generate the encoded input for all movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "152e09fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "def concat(list1, list2):\n",
    "    list1.extend(list2)\n",
    "    return list1\n",
    "\n",
    "EncodedInput = list(reduce(concat, list(i[j] for i in EncodedInput)) for j in range(0, len(Movies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8d3c980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1140\n",
      "[66, 114, 111, 107, 101, 110, 32, 65, 114, 114, 111, 119, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.26313610011962824, 0.21664838846239745, 0, 0.08049054258816266, 108] {'IMDB Votes': 33584, 'Production Budget': 65000000, 'IMDB Rating': 5.8, 'MPAA Rating': 'R', 'Rotten Tomatoes Rating': 55, 'Distributor': '20th Century Fox', 'Director': 'John Woo', 'Creative Type': 'Contemporary Fiction', 'US Gross': 70645997, 'Major Genre': 'Action', 'Worldwide Gross': 148345997, 'Source': 'Original Screenplay', 'Release Date': 'Feb 09 1996', 'Running Time min': 108, 'Title': 'Broken Arrow'}\n"
     ]
    }
   ],
   "source": [
    "print(len(EncodedInput))\n",
    "print(EncodedInput[0], Movies[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8ecbd6",
   "metadata": {},
   "source": [
    "### Groundtruths\n",
    "\n",
    "The groundtruth in this case is the IMDB rating of the 1140 movies. Simply compile the groundtruths based on the movies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f29b82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "GroundTruth = list(i[\"IMDB Rating\"] for i in Movies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e97730e",
   "metadata": {},
   "source": [
    "## Constructing Neural Network\n",
    "\n",
    "Now it's time to make a neural network using basic PyTorch functions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b466b36e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
