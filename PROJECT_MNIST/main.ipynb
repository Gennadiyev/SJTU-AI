{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f42e4bb",
   "metadata": {},
   "source": [
    "# Coursework - Team Untitled\n",
    "\n",
    "## Team Members\n",
    "\n",
    "| Name | Main Contribution |\n",
    "| :-: | :-: |\n",
    "| Ji Yikun | |\n",
    "| Wang Shuqi | |\n",
    "| Chen Qi | |\n",
    "\n",
    "## Setup\n",
    "\n",
    "All codes are tested and run under **Termux**, an Android port of Linux Debian, as a virtual environment. You may need to edit paths and some `os` commands so as to setup everything ready on Windows and other platforms.\n",
    "\n",
    "All packages come native in *Anaconda*, but you should refer to `requirements.txt` to see if everything is set to be the right version.\n",
    "\n",
    "## Open-source License\n",
    "\n",
    "This notebook and its code, illustrations, are under the **MIT** License.\n",
    "\n",
    "```\n",
    "MIT License\n",
    "\n",
    "Copyright (c) 2021 Kunologist, Wang Shuqi and Chen Qi\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0ffbdf",
   "metadata": {},
   "source": [
    "## Basic: MNIST\n",
    "\n",
    "[MNIST](http://yann.lecun.com/exdb/mnist/) is an image classification dataset of recognizing digits. This part is a simple attempt to use basic convolutional neural networks to train a model for recognizing handwritten digits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b2691b",
   "metadata": {},
   "source": [
    "### Import and Environment Settings\n",
    "\n",
    "> You may wish to edit several variables here before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edece78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.dpi']=400\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "device = \"cpu\"\n",
    "rootdir = os.environ['HOME'] + '/pytorch'\n",
    "workdir = \"/storage/emulated/0/Kunologist/Jupyter/LectureNotes/PROJECT_MNIST/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c997e8c8",
   "metadata": {},
   "source": [
    "### Set CNN\n",
    "\n",
    "The following code use a simple convolutional neural network to identify the digit.\n",
    "\n",
    "#### function `Net.__init__()`\n",
    "\n",
    "> **Summary:** Defines the key networks in the `Net`, which is then used in `forward()`.\n",
    "\n",
    "> **Returns:** Nothing (Constructor).\n",
    "\n",
    "| Argument | Type | Description |\n",
    "| :-- | :-- | :-- |\n",
    "| `self` | `Net` | An instance of `Net` |\n",
    "\n",
    "#### function `Net.forward()`\n",
    "\n",
    "> **Summary:** Predicts the digit of the image with respect to the given input `x`.\n",
    "\n",
    "> **Returns:** An output `Tensor` containing the softmax-ed output neurons.\n",
    "\n",
    "| Argument | Type | Description |\n",
    "| :-- | :-- | :-- |\n",
    "| `self` | `Net` | An instance of `Net` |\n",
    "| `x` | `` | The data of the image |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d88bf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cebbd8",
   "metadata": {},
   "source": [
    "### Defining Sub-functions\n",
    "\n",
    "#### function `train()`\n",
    "\n",
    "> **Summary:** Trains the model instance with the given train loader.\n",
    "\n",
    "> **Returns:** Nothing.\n",
    "\n",
    "| Argument | Type | Description |\n",
    "| :-- | :-- | :-- |\n",
    "| `model` | `Net` | An instance of `Net` |\n",
    "| `device` | `torch.device` | Where to train the model |\n",
    "| `train_loader` | `torch.DataLoader` | The `DataLoader` which contains the data source of the images |\n",
    "| `optimizer` | `torch.optim.*.*` | The optimizer, AdaDelta in this case |\n",
    "| `epoch` | `int` | The number of epoch |\n",
    "\n",
    "#### function `test()`\n",
    "\n",
    "> **Summary:** Tests the model (without learning) and prints the accuracy information.\n",
    "\n",
    "> **Returns:** Nothing.\n",
    "\n",
    "| Argument | Type | Description |\n",
    "| :-- | :-- | :-- |\n",
    "| `model` | `Net` | An instance of `Net` |\n",
    "| `device` | `torch.device` | Where to train the model |\n",
    "| `test_loader` | `torch.DataLoader` | The `DataLoader` which contains the data source of the images |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abf97d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 20 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item())\n",
    "            )\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350b24c7",
   "metadata": {},
   "source": [
    "### Runner\n",
    "\n",
    "We use the standard PyTorch model training flow:\n",
    "\n",
    "1. DataLoader for both training and testing\n",
    "2. Optimizer using [AdaDelta](https://pytorch.org/docs/stable/generated/torch.optim.Adadelta.html), a more adaptive alternative to AdaGrad\n",
    "3. Scheduler\n",
    "\n",
    "One thing to mention is, in the preprocess stage, we used `transform.Normalize` to normalize the images. The reason to do this is ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55f4cb36",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        workdir,\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307, ), (0.3081, ))\n",
    "        ])\n",
    "    ),\n",
    "    batch_size=64,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(\n",
    "        workdir,\n",
    "        train=False,\n",
    "        transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307, ), (0.3081, ))\n",
    "        ])),\n",
    "    batch_size=1000,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "model = Net().to(device)\n",
    "optimizer = optim.Adadelta(model.parameters()) # Defaults to learning rate = 1.0 and epsilon = 1e-6\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1316b62d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.293385\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 0.751613\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.394350\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-d97b5d454549>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-bd78ae6d3122>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/user/0/ru.iiec.pydroid3/files/aarch64-linux-android/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-bbf652b63a15>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/user/0/ru.iiec.pydroid3/files/aarch64-linux-android/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/user/0/ru.iiec.pydroid3/files/aarch64-linux-android/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/user/0/ru.iiec.pydroid3/files/aarch64-linux-android/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1608\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1610\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1611\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 5 + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6514b117",
   "metadata": {},
   "source": [
    "### Saving / Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfff8e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/user/0/ru.iiec.pydroid3/files/aarch64-linux-android/lib/python3.8/site-packages/torch/serialization.py:401: UserWarning: Couldn't retrieve source code for container of type Net. It won't be checked for correctness upon loading.\n",
      "  warnings.warn(\"Couldn't retrieve source code for container of \"\n"
     ]
    }
   ],
   "source": [
    "# Creates the directory if not found\n",
    "try:\n",
    "    os.mkdir(workdir + \"models\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Save the model\n",
    "from datetime import datetime\n",
    "model_name = \"models/model-\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "torch.save(model, workdir + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5484015",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"/storage/emulated/0/Kunologist/Jupyter/LectureNotes/PROJECT_MNIST/models/model-20210719-165435\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebea3d85",
   "metadata": {},
   "source": [
    "### Wrapping\n",
    "\n",
    "The model is then wrapped around a `predict()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6a34d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_data, draw_image = False) -> int:\n",
    "    if draw_image:\n",
    "        plt.imshow(image_data.reshape(28, 28), cmap=cm.get_cmap('Greys'))\n",
    "    likelihood = torch.Tensor.tolist(model.forward(image_data.reshape(1,1,28,28)))[0]\n",
    "    pred = 0\n",
    "    conf = max(likelihood)\n",
    "    for i in likelihood:\n",
    "        if i == conf:\n",
    "            return pred\n",
    "            break\n",
    "        pred += 1\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aba60e3",
   "metadata": {},
   "source": [
    "The following code generates an error map on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093eb0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "matr = np.zeros((10, 10))\n",
    "test_data = test_loader.dataset\n",
    "for i in test_data:\n",
    "    matr[i[1]][predict(i[0])] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38e5a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    matr[i][i] = 0\n",
    "plt.xticks(range(10))\n",
    "plt.yticks(range(10))\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Ground Truth')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.imshow(matr, cmap=cm.get_cmap('magma'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d29bef6",
   "metadata": {},
   "source": [
    "## Intermediate: FGSM Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e7d9b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 251.565 248.518125\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <defs>\n",
       "  <style type=\"text/css\">\n",
       "*{stroke-linecap:butt;stroke-linejoin:round;}\n",
       "  </style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 248.518125 \n",
       "L 251.565 248.518125 \n",
       "L 251.565 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 26.925 224.64 \n",
       "L 244.365 224.64 \n",
       "L 244.365 7.2 \n",
       "L 26.925 7.2 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#p89b2086c3d)\">\n",
       "    <image height=\"217.44\" id=\"image475848247d\" transform=\"scale(1 -1)translate(0 -217.44)\" width=\"217.44\" x=\"26.925\" xlink:href=\"data:image/png;base64,\n",
       "iVBORw0KGgoAAAANSUhEUgAABLgAAAS4CAYAAAAUpXFWAAAABHNCSVQICAgIfAhkiAAAIABJREFUeJzs2rGKXWUbhmF3ZhACIYK2UQwIEdEmEYxWliJWgp2FTaaykRQ2QrSwUMFKIQhW9hIbI6JY6QGInY0gSqKFXYxMdP+n8G3+4t33cF1H8LCKtRY372a73W7vAwAAAICoU9MDAAAAAOD/IXABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJB2OD0AAADYH7/88sv0hJ1cvXp1esKya9euTU9Y9tRTT01PWLbZbKYnAHvABRcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpm+12u50eAQAA7IcbN25MT9jJyy+/PD3hRLp79+70hGX333//9ARgD7jgAgAAACBN4AIAAAAgTeACAAAAIE3gAgAAACBN4AIAAAAgTeACAAAAIE3gAgAAACBN4AIAAAAgTeACAAAAIE3gAgAAACBN4AIAAAAgTeACAAAAIE3gAgAAACBN4AIAAAAgTeACAAAAIE3gAgAAACBN4AIAAAAgTeACAAAAIE3gAgAAACBN4AIAAAAgTeACAAAAIE3gAgAAACBN4AIAAAAgTeACAAAAIE3gAgAAACBN4AIAAAAgTeACAAAAIE3gAgAAACBN4AIAAAAgTeACAAAAIE3gAgAAACBN4AIAAAAgTeACAAAAIE3gAgAAACBN4AIAAAAgTeACAAAAIE3gAgAAACBN4AIAAAAgTeACAAAAIE3gAgAAACBN4AIAAAAgTeACAAAAIO1wegAAAAD75ZNPPpmesOz111+fngDsARdcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQdTg8AAABgv7z00kvTEwB24oILAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACAtMPpAQAAwP74448/piewBx5++OHpCQA7ccEFAAAAQJrABQAAAECawAUAAABAmsAFAAAAQJrABQAAAECawAUAAABAmsAFAAAAQJrABQAAAECawAUAAABAmsAFAAAAQJrABQAAAECawAUAAABAmsAFAAAAQJrABQAAAECawAUAAABAmsAFAAAAQJrABQAAAECawAUAAABAmsAFAAAAQJrABQAAAECawAUAAABAmsAFAAAAQJrABQAAAECawAUAAABAmsAFAAAAQJrABQAAAECawAUAAABAmsAFAAAAQJrABQAAAECawAUAAABAmsAFAAAAQJrABQAAAECawAUAAABAmsAFAAAAQJrABQAAAECawAUAAABAmsAFAAAAQJrABQAAAECawAUAAABAmsAFAAAAQJrABQAAAECawAUAAABA2ma73W6nRwDALo6Pj6cnLPvoo4+mJ+zk/Pnz0xOWffPNN9MTlj3xxBPTE5YdHR1NT1h2eHg4PeFEOnfu3PSEnfz+++/TE06k0rf24OBgegKwB1xwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJB2OD0AgP3w119/TU9Y9t57701PWPb+++9PT4CdXLx4cXrCsqeffnp6wrLDw85v99HR0fSEnbz99tvTEwDYAy64AAAAAEgTuAAAAABIE7gAAAAASBO4AAAAAEgTuAAAAABIE7gAAAAASBO4AAAAAEgTuAAAAABIE7gAAAAASBO4AAAAAEgTuAAAAABIE7gAAAAASBO4AAAAAEgTuAAAAABIE7gAAAAASBO4AAAAAEgTuAAAAABIE7gAAAAASBO4AAAAAEgTuAAAAABIE7gAAAAASBO4AAAAAEgTuAAAAABIE7gAAAAASBO4AAAAAEgTuAAAAABIE7gAAAAASBO4AAAAAEgTuAAAAABIE7gAAAAASBO4AAAAAEgTuAAAAABIE7gAAAAASBO4AAAAAEgTuAAAAABIE7gAAAAASBO4AAAAAEgTuAAAAABIE7gAAAAASBO4AAAAAEgTuAAAAABIE7gAAAAASDucHgCwq+Pj4+kJy3777bfpCcveeOON6QnLvvjii+kJyx544IHpCTt55plnpicsu3Xr1vSEZT/++OP0hGXPPffc9IRl169fn56w7OjoaHrCsrNnz05PAICdueACAAAAIE3gAgAAACBN4AIAAAAgTeACAAAAIE3gAgAAACBN4AIAAAAgTeACAAAAIE3gAgAAACBN4AIAAAAgTeACAAAAIE3gAgAAACBN4AIAAAAgTeACAAAAIE3gAgAAACBN4AIAAAAgTeACAAAAIE3gAgAAACBN4AIAAAAgTeACAAAAIE3gAgAAACBN4AIAAAAgTeACAAAAIE3gAgAAACBN4AIAAAAgTeACAAAAIE3gAgAAACBN4AIAAAAgTeACAAAAIE3gAgAAACBN4AIAAAAgTeACAAAAIE3gAgAAACBN4AIAAAAgTeACAAAAIE3gAgAAACBN4AIAAAAgTeACAAAAIE3gAgAAACBN4AIAAAAgTeACAAAAIE3gAgAAACBN4AIAAAAgbbPdbrfTI4B59+7dm56w7IcffpiesOz555+fnnAiXbx4cXrCss8//3x6wk4eeeSR6QnL7ty5Mz1h2c2bN6cnLHvttdemJyx78MEHpycsu3HjxvSEZS+88ML0hJ38+eef0xNOpOPj4+kJyw4ODqYnAHvABRcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpm+12u50eASfVvXv3picse+edd6YnLHv33XenJ5xITz755PSEZV9++eX0hGXnzp2bngA7efPNN6cnLPv444+nJyy7c+fO9ATYyfHx8fSEZQcHB9MTgD3gggsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIC0zXa73U6PgJPq559/np6w7MKFC9MTTqSzZ89OT1h28+bN6QnLnn322ekJwB749NNPpycsu3LlyvQE9sDjjz8+PWHZTz/9ND1h2alT7jYAF1wAAAAAxAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkbbbb7XZ6BKy6e/fu9ISdnD9/fnrCstu3b09PWHbmzJnpCcu+/vrr6QnLLl++PD0BYCd///339IRlFy5cmJ6w7Ndff52esJPNZjM9YdkHH3wwPWHZ1atXpycA7MQFFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGmH0wOY9++//05PWPbWW29NT9jJ7du3pyecSI8++uj0hGWXL1+engBwYp0+fXp6wrJr165NT1h25cqV6QkAsDMXXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkbbbb7XZ6BLP++eef6QnLTp8+PT3hxDpz5sz0hGXffffd9IRlly5dmp4AwB746quvpicse/HFF6cnnFgPPfTQ9IRlt27dmp6w7ODgYHoCsAdccAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJB2OD2AeZ999tn0BPbA9evXpycsu3Tp0vQEADixttvt9ISdbDab6QnLHnvssekJy0rPFeC++1xwAQAAABAncAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkHY4PeCk+u+//6YnLPv222+nJ5xYr7766vSEZa+88sr0BAA4sb7//vvpCeyBDz/8cHrCslOn3EIALd5aAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAACkCVwAAAAApAlcAAAAAKQJXAAAAMD/2rVjm8aiKIqismRZcgHugAqogBoowv04pwhiOiAkRhRABxD9aeH9kUZ3trVWBSd7elsX0gQuAAAAANIELgAAAADSBC4AAAAA0gQuAAAAANIELgAAAADSBC4AAAAA0gQuAAAAANIELgAAAADSBC4AAAAA0gQuAAAAANIELgAAAADSBC4AAAAA0gQuAAAAANIELgAAAADSBC4AAAAA0gQuAAAAANIELgAAAADSBC4AAAAA0gQuAAAAANIELgAAAADSBC4AAAAA0gQuAAAAANIELgAAAADSBC4AAAAA0gQuAAAAANIELgAAAADSBC4AAAAA0gQuAAAAANIELgAAAADSBC4AAAAA0gQuAAAAANIO27Zt0yPu0cvLy/SEZdfrdXrCsvP5PD1hl4+Pj+kJyx4eHqYnAMDdKr2zX19f0xN2ORwO0xOW/fz8TE9YdjqdpicA7OKCCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgLTDtm3b9Ih79Pv7Oz1h2fl8np6w7HK5TE/Y5fv7e3oCAPAfeH19nZ6w7Pn5eXrCLk9PT9MTlr29vU1PWHY8HqcnAOziggsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIA0gQsAAACANIELAAAAgDSBCwAAAIC04/SAe3U6naYnLHt/f5+esOzz83N6AgDAbo+Pj9MTlt1ut+kJu1yv1+kJy45H3y+Af8UFFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGkCFwAAAABpAhcAAAAAaQIXAAAAAGmHbdu26REAAAAA8LdccAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCa/nm5OAAAFw0lEQVRwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkCZwAQAAAJAmcAEAAACQJnABAAAAkPYHuFIGrEPay1QAAAAASUVORK5CYII=\" y=\"-7.2\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"m7bb201ed4c\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.807857\" xlink:href=\"#m7bb201ed4c\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <defs>\n",
       "       <path d=\"M 31.78125 66.40625 \n",
       "Q 24.171875 66.40625 20.328125 58.90625 \n",
       "Q 16.5 51.421875 16.5 36.375 \n",
       "Q 16.5 21.390625 20.328125 13.890625 \n",
       "Q 24.171875 6.390625 31.78125 6.390625 \n",
       "Q 39.453125 6.390625 43.28125 13.890625 \n",
       "Q 47.125 21.390625 47.125 36.375 \n",
       "Q 47.125 51.421875 43.28125 58.90625 \n",
       "Q 39.453125 66.40625 31.78125 66.40625 \n",
       "z\n",
       "M 31.78125 74.21875 \n",
       "Q 44.046875 74.21875 50.515625 64.515625 \n",
       "Q 56.984375 54.828125 56.984375 36.375 \n",
       "Q 56.984375 17.96875 50.515625 8.265625 \n",
       "Q 44.046875 -1.421875 31.78125 -1.421875 \n",
       "Q 19.53125 -1.421875 13.0625 8.265625 \n",
       "Q 6.59375 17.96875 6.59375 36.375 \n",
       "Q 6.59375 54.828125 13.0625 64.515625 \n",
       "Q 19.53125 74.21875 31.78125 74.21875 \n",
       "z\n",
       "\" id=\"DejaVuSans-48\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(27.626607 239.238437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.636429\" xlink:href=\"#m7bb201ed4c\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 5 -->\n",
       "      <defs>\n",
       "       <path d=\"M 10.796875 72.90625 \n",
       "L 49.515625 72.90625 \n",
       "L 49.515625 64.59375 \n",
       "L 19.828125 64.59375 \n",
       "L 19.828125 46.734375 \n",
       "Q 21.96875 47.46875 24.109375 47.828125 \n",
       "Q 26.265625 48.1875 28.421875 48.1875 \n",
       "Q 40.625 48.1875 47.75 41.5 \n",
       "Q 54.890625 34.8125 54.890625 23.390625 \n",
       "Q 54.890625 11.625 47.5625 5.09375 \n",
       "Q 40.234375 -1.421875 26.90625 -1.421875 \n",
       "Q 22.3125 -1.421875 17.546875 -0.640625 \n",
       "Q 12.796875 0.140625 7.71875 1.703125 \n",
       "L 7.71875 11.625 \n",
       "Q 12.109375 9.234375 16.796875 8.0625 \n",
       "Q 21.484375 6.890625 26.703125 6.890625 \n",
       "Q 35.15625 6.890625 40.078125 11.328125 \n",
       "Q 45.015625 15.765625 45.015625 23.390625 \n",
       "Q 45.015625 31 40.078125 35.4375 \n",
       "Q 35.15625 39.890625 26.703125 39.890625 \n",
       "Q 22.75 39.890625 18.8125 39.015625 \n",
       "Q 14.890625 38.140625 10.796875 36.28125 \n",
       "z\n",
       "\" id=\"DejaVuSans-53\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(66.455179 239.238437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.465\" xlink:href=\"#m7bb201ed4c\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 10 -->\n",
       "      <defs>\n",
       "       <path d=\"M 12.40625 8.296875 \n",
       "L 28.515625 8.296875 \n",
       "L 28.515625 63.921875 \n",
       "L 10.984375 60.40625 \n",
       "L 10.984375 69.390625 \n",
       "L 28.421875 72.90625 \n",
       "L 38.28125 72.90625 \n",
       "L 38.28125 8.296875 \n",
       "L 54.390625 8.296875 \n",
       "L 54.390625 0 \n",
       "L 12.40625 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-49\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(102.1025 239.238437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.293571\" xlink:href=\"#m7bb201ed4c\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 15 -->\n",
       "      <g transform=\"translate(140.931071 239.238437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.122143\" xlink:href=\"#m7bb201ed4c\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 20 -->\n",
       "      <defs>\n",
       "       <path d=\"M 19.1875 8.296875 \n",
       "L 53.609375 8.296875 \n",
       "L 53.609375 0 \n",
       "L 7.328125 0 \n",
       "L 7.328125 8.296875 \n",
       "Q 12.9375 14.109375 22.625 23.890625 \n",
       "Q 32.328125 33.6875 34.8125 36.53125 \n",
       "Q 39.546875 41.84375 41.421875 45.53125 \n",
       "Q 43.3125 49.21875 43.3125 52.78125 \n",
       "Q 43.3125 58.59375 39.234375 62.25 \n",
       "Q 35.15625 65.921875 28.609375 65.921875 \n",
       "Q 23.96875 65.921875 18.8125 64.3125 \n",
       "Q 13.671875 62.703125 7.8125 59.421875 \n",
       "L 7.8125 69.390625 \n",
       "Q 13.765625 71.78125 18.9375 73 \n",
       "Q 24.125 74.21875 28.421875 74.21875 \n",
       "Q 39.75 74.21875 46.484375 68.546875 \n",
       "Q 53.21875 62.890625 53.21875 53.421875 \n",
       "Q 53.21875 48.921875 51.53125 44.890625 \n",
       "Q 49.859375 40.875 45.40625 35.40625 \n",
       "Q 44.1875 33.984375 37.640625 27.21875 \n",
       "Q 31.109375 20.453125 19.1875 8.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-50\"/>\n",
       "      </defs>\n",
       "      <g transform=\"translate(179.759643 239.238437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"224.950714\" xlink:href=\"#m7bb201ed4c\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 25 -->\n",
       "      <g transform=\"translate(218.588214 239.238437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"m7d771c5635\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m7d771c5635\" y=\"11.082857\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(13.5625 14.882076)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m7d771c5635\" y=\"49.911429\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 5 -->\n",
       "      <g transform=\"translate(13.5625 53.710647)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m7d771c5635\" y=\"88.74\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 10 -->\n",
       "      <g transform=\"translate(7.2 92.539219)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m7d771c5635\" y=\"127.568571\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 15 -->\n",
       "      <g transform=\"translate(7.2 131.36779)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m7d771c5635\" y=\"166.397143\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 20 -->\n",
       "      <g transform=\"translate(7.2 170.196362)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m7d771c5635\" y=\"205.225714\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 25 -->\n",
       "      <g transform=\"translate(7.2 209.024933)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 26.925 224.64 \n",
       "L 26.925 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 244.365 224.64 \n",
       "L 244.365 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 26.925 224.64 \n",
       "L 244.365 224.64 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 26.925 7.2 \n",
       "L 244.365 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p89b2086c3d\">\n",
       "   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"7.2\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 2400x1600 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data = test_loader.dataset\n",
    "predict(test_data[1145][0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257b22f6",
   "metadata": {},
   "source": [
    "In this part we will perform FGSM attack towards the model.\n",
    "\n",
    "### About FGSM\n",
    "\n",
    "FGSM is a typical adversarial white-box attack method, which targets the foundamental logic of neural networks: gradients. The main formula behind this idea is:\n",
    "\n",
    "$$\n",
    "\\dfrac{\\eta}{\\varepsilon} = \\text{sgn}\\left(\\nabla_{\\mathbf{x}} \\mathcal{J}(\\theta, \\mathbf{x}, y)\\right)\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $\\varepsilon$ is the rate of pertubation, the larger the value, the stronger the attack\n",
    "- $\\text{sgn}(x) = \\begin{cases}\\begin{aligned}\n",
    "1 \\quad &(x > 0) \\\\\n",
    "0 \\quad &(x = 0) \\\\\n",
    "-1 \\quad &(x < 0)\n",
    "\\end{aligned}\\end{cases}$\n",
    "- $\\nabla_x$ means to take the partial derivative of $\\mathbf{x}$\n",
    "- $\\theta$ represents the whole model, it consists of all parameters within `model`.\n",
    "- $\\mathcal{J}$ is the cost function\n",
    "- $\\mathbf{x}$ is the input image data\n",
    "- $y$ is the ground-truth label\n",
    "\n",
    "and the preturbed image:\n",
    "\n",
    "$$\n",
    "\\text{perturbed_image}=\\text{image}+\\varepsilon \\text{sgn}\\left(\\nabla_x \\mathcal{J}(\\theta,x,y)\\right)=\\text{image}+\\eta\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "427fa6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=3\n",
    "epsilon=0.25\n",
    "attack_accuracy_record=np.zeros(k)\n",
    "attack_image_record=list()\n",
    "\n",
    "def FGSM(data,epsilon,data_grad):\n",
    "    sign_data_grad=data_grad.sign()\n",
    "    attacked_data=data+epsilon*sign_data_grad\n",
    "    attacked_data=torch.clamp(attacked_data,0,1)\n",
    "    return attacked_data\n",
    "def attack_test(model,test_loader,k,epsilon):\n",
    "    correct=0\n",
    "    count=0\n",
    "    for batch, (data,target) in enumerate(test_loader):\n",
    "        data.requires_grad=True\n",
    "        for i in range(k):\n",
    "            data.retain_grad()\n",
    "            model.zero_grad()\n",
    "            data_temp=data+torch.Tensor(np.random.uniform(-epsilon,epsilon,data.shape))\n",
    "            result=model(data_temp)\n",
    "            attack_test_loss=F.nll_loss(result, target)\n",
    "            pred=result.argmax(dim=1,keepdim=True)\n",
    "            accuracy=pred.eq(target.view_as(pred)).sum().item()\n",
    "            attack_accuracy_record[i]+=accuracy\n",
    "            if(i==k-1)and(count<5)and(accuracy==0):\n",
    "                temp={\n",
    "                    'data':data.detach().reshape(28,28),\n",
    "                    'target':int(target),\n",
    "                    'result':int(pred)\n",
    "                }\n",
    "                attack_image_record.append(temp)\n",
    "                count+=1\n",
    "            attack_test_loss.backward(retain_graph=True)\n",
    "            data_grad=data.grad.data\n",
    "            data=FGSM(data_temp,epsilon,data_grad)\n",
    "            if((batch+1)%500==0) and (i==k-1):\n",
    "                for j in range(k):\n",
    "                    print(\"Attack{}:\\tAccuracy:{}/{}({:.2f}%)\".format(j,attack_accuracy_record[j],(batch+1),\n",
    "                                                                      100.*attack_accuracy_record[j]/(batch+1)))\n",
    "    for i in range(k):\n",
    "        print(\"Attack Test Set:\\tAttack Times{}\\tAccuracy:{}/{}({}%)\".format(i,attack_accuracy_record[i],\n",
    "                                                                            len(test_loader.dataset),\n",
    "                                                                            100.*attack_accuracy_record[i]/\n",
    "                                                                             len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9048709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Split: test\n",
      "    Root Location: /storage/emulated/0/Kunologist/Jupyter/LectureNotes/PROJECT_MNIST/\n",
      "    Transforms (if any): Compose(\n",
      "                             ToTensor()\n",
      "                             Normalize(mean=(0.1307,), std=(0.3081,))\n",
      "                         )\n",
      "    Target Transforms (if any): None\n",
      "Attack Test Set:\tAttack Times0\tAccuracy:9906.0/10000(99.06%)\n",
      "Attack Test Set:\tAttack Times1\tAccuracy:9516.0/10000(95.16%)\n",
      "Attack Test Set:\tAttack Times2\tAccuracy:480.0/10000(4.8%)\n"
     ]
    }
   ],
   "source": [
    "attack_test(model,test_loader,k,epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e5ea62",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "A lot of online resources guided us through the maze. The followings are the most helpful ones. After each reference also attached is what I feel the most important about the reference source.\n",
    "\n",
    "1. [PyTorch Dataset Normalization - `torchvision.transforms.Normalize()`](https://deeplizard.com/learn/video/lu7TCu7HeYc)\n",
    "\n",
    "  I turned to this website for help when I'm thinking about how to normalize the dataset. I guess there must be related utilities I can use in PyTorch, and this article guided me how should I perform the normalization, and why should we do this.\n",
    "\n",
    "\n",
    "2. [AdaDelta Explained](https://www.paperswithcode.com/method/adadelta)\n",
    "\n",
    "  When I'm wondering which optimizer function to use, scrolling through each type in PyTorch docs, a few functions were selected for test. After repetitve tests, AdaDelta outperforms the rest in fields of accuracy. This article shows how AdaDelta works and why it makes sense here in the task of MNIST.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
